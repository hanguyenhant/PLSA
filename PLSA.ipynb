{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PLSA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanguyenhant/PLSA/blob/master/PLSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2wOSPQstqtk",
        "colab_type": "code",
        "outputId": "c3d3a5e6-ae73-4355-bb05-2b72866a6024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3wUksNEtuwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/PLSA')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvrBz6wwt0wF",
        "colab_type": "code",
        "outputId": "976b2bac-3b53-419f-d049-d4d0150d9f45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive/PLSA"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_vectorizer.txt  PLSA.ipynb  vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1OPtxIqt2Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg8hslR7t6rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(path):\n",
        "\tK = 5 #number_of_topics\n",
        "\n",
        "\twith open('/content/gdrive/My Drive/PLSA/vocab.txt', errors = 'ignore') as f:\n",
        "\t\tlines = f.read().splitlines() #number_of_words_in_vocab\n",
        "\n",
        "\tV = len(lines)+1\n",
        "\n",
        "\twith open(path, errors = 'ignore') as f:\n",
        "\t\tlines = f.read().splitlines()\n",
        "\n",
        "\tD = len(lines) #number_of_docs\n",
        "\n",
        "\tdoc_count = []\n",
        "\n",
        "\tfor line in lines:\n",
        "\n",
        "\t\tword_count = dict()\n",
        "\t\twords = line.split('<fff>')[2].split()\n",
        "\n",
        "\t\tfor word in words:\n",
        "\t\t\tword_count[int(word.split(':')[0])] = int(word.split(':')[1])\n",
        "\n",
        "\t\tdoc_count.append(word_count) #doc_count có dạng: [{10:2, 12:3}, {11:3, 13:1, 12:4}, {4:2, 2:4, 1:2, 5:2}]\n",
        "\n",
        "\treturn K, V, D, doc_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKg_OjfTt9AF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PLSA:\n",
        "\tdef __init__(self, K, V, D, doc_count):\n",
        "\n",
        "\t\tself._K = K #number_of_topics\n",
        "\t\tself._V = V #number_of_words_in_vocab\n",
        "\t\tself._D = D #number_of_docs\n",
        "\t\tself._doc_count = doc_count\n",
        "\n",
        "\t\t#X = wordcountPerdoc\n",
        "\t\tself._X = np.zeros(shape = (D, V))\n",
        "\t\tfor i, d in enumerate(self._doc_count):\n",
        "\t\t\tfor key, value in d.items():\n",
        "\t\t\t\tself._X[i][key] = value\n",
        "\n",
        "\t\tself._theta = np.random.random(size = (D, K))\n",
        "\t\tself._beta = np.random.random(size = (K, V))\n",
        "\t\tself._T = np.zeros(shape = (D, V, K))\n",
        "\n",
        "\tdef normalize(self):\n",
        "\t\tfor d in range(self._D):\n",
        "\n",
        "\t\t\tnormalization = np.sum(self._theta[d, :])\n",
        "\n",
        "\t\t\tfor k in range(self._K):\n",
        "\t\t\t\tself._theta[d, k] /= normalization\n",
        "\n",
        "\t\tfor k in range(self._K):\n",
        "\n",
        "\t\t\tnormalization = np.sum(self._beta[k, :])\n",
        "\n",
        "\t\t\tfor v in range(self._V):\n",
        "\t\t\t\tself._beta[k, v] /= normalization\n",
        "\n",
        "\tdef E_step(self):\n",
        "\t\tfor d in range(self._D):\n",
        "\t\t\tfor v in range(self._V):\n",
        "\n",
        "\t\t\t\tdenominator = 0\n",
        "\n",
        "\t\t\t\tfor k in range(self._K):\n",
        "\t\t\t\t\tself._T[d, v, k] = self._theta[d, k] * self._beta[k, v]\n",
        "\t\t\t\t\tdenominator += self._T[d, v, k]\n",
        "\n",
        "\t\t\t\tif denominator == 0:\n",
        "\t\t\t\t\tfor k in range(self._K):\n",
        "\t\t\t\t\t\tself._T[d, v, k] = 0;\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tfor k in range(self._K):\n",
        "\t\t\t\t\t\tself._T[d, v, k] /= denominator;\n",
        "\n",
        "\tdef M_step(self):\n",
        "\t\t#Tinh theta\n",
        "\t\tfor d in range(self._D):\n",
        "\t\t\tfor k in range(self._K):\n",
        "\n",
        "\t\t\t\tself._theta[d, k] = 0\n",
        "\t\t\t\tdenominator = 0\n",
        "\n",
        "\t\t\t\tfor v in range(self._V):\n",
        "\t\t\t\t\tself._theta[d, k] += self._X[d, v] * self._T[d, v, k]\n",
        "\t\t\t\t\tdenominator += self._X[d, v]\n",
        "\n",
        "\n",
        "\t\t\t\tif denominator == 0:\n",
        "\t\t\t\t\tself._theta[d, k] = 1.0 / K\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tself._theta[d, k] /= denominator\n",
        "\n",
        "\t\t#Tinh beta\n",
        "\t\tfor k in range(self._K):\n",
        "\n",
        "\t\t\tdenominator = 0\n",
        "\t\t\tprint('K: ', k)\n",
        "\n",
        "\t\t\tfor v in range(self._V):\n",
        "\n",
        "\t\t\t\tself._beta[k, v] = 0\n",
        "\n",
        "\t\t\t\tfor d in range(self._D):\n",
        "\t\t\t\t\tself._beta[k, v] += self._X[d, v] * self._T[d, v, k]\n",
        "\n",
        "\t\t\t\tdenominator += self._beta[k, v]\n",
        "\n",
        "\t\t\tif denominator == 0:\n",
        "\t\t\t\tfor v in range(self._V):\n",
        "\t\t\t\t\tself._beta[k, v] = 1.0 / self._V\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor v in range(self._V):\n",
        "\t\t\t\t\tself._beta[k, v] /= denominator\n",
        "\n",
        "\tdef LogLikelihood(self):\n",
        "\t\tloglikelihood = 0\n",
        "\n",
        "\t\tfor d in range(self._D):\n",
        "\t\t\tfor v in range(self._V):\n",
        "\t\t\t\ttmp = 0\n",
        "\t\t\t\tfor k in range(self._K):\n",
        "\t\t\t\t\ttmp += self._theta[d, k] * self._beta[k, v]\n",
        "\n",
        "\t\t\t\tif tmp > 0:\n",
        "\t\t\t\t\tloglikelihood += self._X[d, v] * np.log(tmp)\n",
        "\t\treturn loglikelihood"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjoSDJM6t_s2",
        "colab_type": "code",
        "outputId": "64d466f0-cefb-4edc-ccd6-7f1086baf9f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "K, V, D, doc_count = prepare_data('/content/gdrive/My Drive/PLSA/data_vectorizer.txt')\n",
        "\n",
        "print('K, V, D', K, V, D)\n",
        "plsa = PLSA(K, V, D, doc_count)\n",
        "plsa.normalize()\n",
        "\n",
        "L = 0\n",
        "\n",
        "for i in range(100):\n",
        "  plsa.E_step()\n",
        "  print('E_step lan ', i+1)\n",
        "  plsa.M_step()\n",
        "  print('M_step lan ', i+1)\n",
        "  print(\"[\", time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())), \"] After the\", i+1, \"'s iteration  \", )\n",
        "  L_new = plsa.LogLikelihood()\n",
        "  print('Log Likelihood: ', L_new)\n",
        "  print('Loss: ', abs(L - L_new))\n",
        "  if abs(L - L_new) <= 10e-4:\n",
        "    break\n",
        "  else:\n",
        "    L = L_new"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K, V, D 5 5565 249\n",
            "E_step lan  1\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  1\n",
            "[ 2019-07-15 01:19:41 ] After the 1 's iteration  \n",
            "Log Likelihood:  -99349.01466508296\n",
            "Loss:  99349.01466508296\n",
            "E_step lan  2\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  2\n",
            "[ 2019-07-15 01:20:12 ] After the 2 's iteration  \n",
            "Log Likelihood:  -97595.08953603255\n",
            "Loss:  1753.9251290504035\n",
            "E_step lan  3\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  3\n",
            "[ 2019-07-15 01:20:42 ] After the 3 's iteration  \n",
            "Log Likelihood:  -95265.83465088146\n",
            "Loss:  2329.2548851510946\n",
            "E_step lan  4\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  4\n",
            "[ 2019-07-15 01:21:13 ] After the 4 's iteration  \n",
            "Log Likelihood:  -92871.84599013095\n",
            "Loss:  2393.988660750503\n",
            "E_step lan  5\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  5\n",
            "[ 2019-07-15 01:21:44 ] After the 5 's iteration  \n",
            "Log Likelihood:  -90834.72988878695\n",
            "Loss:  2037.1161013439996\n",
            "E_step lan  6\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  6\n",
            "[ 2019-07-15 01:22:14 ] After the 6 's iteration  \n",
            "Log Likelihood:  -89255.65801329559\n",
            "Loss:  1579.0718754913687\n",
            "E_step lan  7\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  7\n",
            "[ 2019-07-15 01:22:45 ] After the 7 's iteration  \n",
            "Log Likelihood:  -88125.39133966074\n",
            "Loss:  1130.2666736348474\n",
            "E_step lan  8\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  8\n",
            "[ 2019-07-15 01:23:16 ] After the 8 's iteration  \n",
            "Log Likelihood:  -87356.119009999\n",
            "Loss:  769.2723296617332\n",
            "E_step lan  9\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  9\n",
            "[ 2019-07-15 01:23:46 ] After the 9 's iteration  \n",
            "Log Likelihood:  -86834.69309535815\n",
            "Loss:  521.4259146408585\n",
            "E_step lan  10\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  10\n",
            "[ 2019-07-15 01:24:17 ] After the 10 's iteration  \n",
            "Log Likelihood:  -86502.5448867119\n",
            "Loss:  332.14820864624926\n",
            "E_step lan  11\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  11\n",
            "[ 2019-07-15 01:24:48 ] After the 11 's iteration  \n",
            "Log Likelihood:  -86295.45567361456\n",
            "Loss:  207.08921309733705\n",
            "E_step lan  12\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  12\n",
            "[ 2019-07-15 01:25:18 ] After the 12 's iteration  \n",
            "Log Likelihood:  -86158.38361681442\n",
            "Loss:  137.07205680014158\n",
            "E_step lan  13\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  13\n",
            "[ 2019-07-15 01:25:49 ] After the 13 's iteration  \n",
            "Log Likelihood:  -86052.05991612922\n",
            "Loss:  106.32370068519958\n",
            "E_step lan  14\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  14\n",
            "[ 2019-07-15 01:26:19 ] After the 14 's iteration  \n",
            "Log Likelihood:  -85973.48612911918\n",
            "Loss:  78.573787010042\n",
            "E_step lan  15\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  15\n",
            "[ 2019-07-15 01:26:50 ] After the 15 's iteration  \n",
            "Log Likelihood:  -85919.68822819903\n",
            "Loss:  53.79790092015173\n",
            "E_step lan  16\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  16\n",
            "[ 2019-07-15 01:27:21 ] After the 16 's iteration  \n",
            "Log Likelihood:  -85883.52880466093\n",
            "Loss:  36.15942353809078\n",
            "E_step lan  17\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  17\n",
            "[ 2019-07-15 01:27:51 ] After the 17 's iteration  \n",
            "Log Likelihood:  -85855.02534181003\n",
            "Loss:  28.503462850901997\n",
            "E_step lan  18\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  18\n",
            "[ 2019-07-15 01:28:22 ] After the 18 's iteration  \n",
            "Log Likelihood:  -85836.3183702566\n",
            "Loss:  18.706971553430776\n",
            "E_step lan  19\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  19\n",
            "[ 2019-07-15 01:28:53 ] After the 19 's iteration  \n",
            "Log Likelihood:  -85825.02575107822\n",
            "Loss:  11.292619178377208\n",
            "E_step lan  20\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  20\n",
            "[ 2019-07-15 01:29:23 ] After the 20 's iteration  \n",
            "Log Likelihood:  -85815.48911922002\n",
            "Loss:  9.536631858209148\n",
            "E_step lan  21\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  21\n",
            "[ 2019-07-15 01:29:54 ] After the 21 's iteration  \n",
            "Log Likelihood:  -85808.7544820995\n",
            "Loss:  6.734637120520347\n",
            "E_step lan  22\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  22\n",
            "[ 2019-07-15 01:30:25 ] After the 22 's iteration  \n",
            "Log Likelihood:  -85805.96479612743\n",
            "Loss:  2.789685972064035\n",
            "E_step lan  23\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  23\n",
            "[ 2019-07-15 01:30:56 ] After the 23 's iteration  \n",
            "Log Likelihood:  -85804.86104870796\n",
            "Loss:  1.10374741947453\n",
            "E_step lan  24\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  24\n",
            "[ 2019-07-15 01:31:27 ] After the 24 's iteration  \n",
            "Log Likelihood:  -85803.80916206386\n",
            "Loss:  1.0518866440979764\n",
            "E_step lan  25\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  25\n",
            "[ 2019-07-15 01:31:58 ] After the 25 's iteration  \n",
            "Log Likelihood:  -85802.82373771067\n",
            "Loss:  0.9854243531881366\n",
            "E_step lan  26\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  26\n",
            "[ 2019-07-15 01:32:29 ] After the 26 's iteration  \n",
            "Log Likelihood:  -85801.73932340754\n",
            "Loss:  1.084414303128142\n",
            "E_step lan  27\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  27\n",
            "[ 2019-07-15 01:33:00 ] After the 27 's iteration  \n",
            "Log Likelihood:  -85800.11963599968\n",
            "Loss:  1.619687407859601\n",
            "E_step lan  28\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  28\n",
            "[ 2019-07-15 01:33:31 ] After the 28 's iteration  \n",
            "Log Likelihood:  -85798.95187731503\n",
            "Loss:  1.1677586846490158\n",
            "E_step lan  29\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  29\n",
            "[ 2019-07-15 01:34:02 ] After the 29 's iteration  \n",
            "Log Likelihood:  -85798.00539306804\n",
            "Loss:  0.9464842469897121\n",
            "E_step lan  30\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  30\n",
            "[ 2019-07-15 01:34:33 ] After the 30 's iteration  \n",
            "Log Likelihood:  -85796.70075976387\n",
            "Loss:  1.3046333041711478\n",
            "E_step lan  31\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  31\n",
            "[ 2019-07-15 01:35:04 ] After the 31 's iteration  \n",
            "Log Likelihood:  -85794.58956725066\n",
            "Loss:  2.1111925132136093\n",
            "E_step lan  32\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  32\n",
            "[ 2019-07-15 01:35:35 ] After the 32 's iteration  \n",
            "Log Likelihood:  -85791.0025872059\n",
            "Loss:  3.586980044754455\n",
            "E_step lan  33\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  33\n",
            "[ 2019-07-15 01:36:06 ] After the 33 's iteration  \n",
            "Log Likelihood:  -85785.09092191479\n",
            "Loss:  5.91166529111797\n",
            "E_step lan  34\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  34\n",
            "[ 2019-07-15 01:36:37 ] After the 34 's iteration  \n",
            "Log Likelihood:  -85777.02364633634\n",
            "Loss:  8.067275578447152\n",
            "E_step lan  35\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  35\n",
            "[ 2019-07-15 01:37:08 ] After the 35 's iteration  \n",
            "Log Likelihood:  -85770.01665875001\n",
            "Loss:  7.0069875863264315\n",
            "E_step lan  36\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  36\n",
            "[ 2019-07-15 01:37:39 ] After the 36 's iteration  \n",
            "Log Likelihood:  -85766.76792823631\n",
            "Loss:  3.2487305137037765\n",
            "E_step lan  37\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  37\n",
            "[ 2019-07-15 01:38:10 ] After the 37 's iteration  \n",
            "Log Likelihood:  -85765.52806321831\n",
            "Loss:  1.2398650179966353\n",
            "E_step lan  38\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  38\n",
            "[ 2019-07-15 01:38:41 ] After the 38 's iteration  \n",
            "Log Likelihood:  -85764.54939398737\n",
            "Loss:  0.9786692309426144\n",
            "E_step lan  39\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  39\n",
            "[ 2019-07-15 01:39:12 ] After the 39 's iteration  \n",
            "Log Likelihood:  -85763.14996074868\n",
            "Loss:  1.3994332386937458\n",
            "E_step lan  40\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  40\n",
            "[ 2019-07-15 01:39:42 ] After the 40 's iteration  \n",
            "Log Likelihood:  -85761.24294136408\n",
            "Loss:  1.907019384598243\n",
            "E_step lan  41\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  41\n",
            "[ 2019-07-15 01:40:13 ] After the 41 's iteration  \n",
            "Log Likelihood:  -85759.66913124657\n",
            "Loss:  1.5738101175084012\n",
            "E_step lan  42\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  42\n",
            "[ 2019-07-15 01:40:43 ] After the 42 's iteration  \n",
            "Log Likelihood:  -85758.50589588136\n",
            "Loss:  1.1632353652094025\n",
            "E_step lan  43\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  43\n",
            "[ 2019-07-15 01:41:13 ] After the 43 's iteration  \n",
            "Log Likelihood:  -85757.35718534733\n",
            "Loss:  1.1487105340347625\n",
            "E_step lan  44\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  44\n",
            "[ 2019-07-15 01:41:43 ] After the 44 's iteration  \n",
            "Log Likelihood:  -85756.43485966785\n",
            "Loss:  0.9223256794793997\n",
            "E_step lan  45\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  45\n",
            "[ 2019-07-15 01:42:14 ] After the 45 's iteration  \n",
            "Log Likelihood:  -85755.97370801833\n",
            "Loss:  0.46115164952061605\n",
            "E_step lan  46\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  46\n",
            "[ 2019-07-15 01:42:44 ] After the 46 's iteration  \n",
            "Log Likelihood:  -85755.73867520112\n",
            "Loss:  0.2350328172033187\n",
            "E_step lan  47\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  47\n",
            "[ 2019-07-15 01:43:14 ] After the 47 's iteration  \n",
            "Log Likelihood:  -85755.61566660114\n",
            "Loss:  0.12300859998504166\n",
            "E_step lan  48\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  48\n",
            "[ 2019-07-15 01:43:44 ] After the 48 's iteration  \n",
            "Log Likelihood:  -85755.54450370936\n",
            "Loss:  0.07116289177793078\n",
            "E_step lan  49\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  49\n",
            "[ 2019-07-15 01:44:15 ] After the 49 's iteration  \n",
            "Log Likelihood:  -85755.49371076583\n",
            "Loss:  0.050792943526175804\n",
            "E_step lan  50\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  50\n",
            "[ 2019-07-15 01:44:45 ] After the 50 's iteration  \n",
            "Log Likelihood:  -85755.45088931051\n",
            "Loss:  0.04282145532488357\n",
            "E_step lan  51\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  51\n",
            "[ 2019-07-15 01:45:16 ] After the 51 's iteration  \n",
            "Log Likelihood:  -85755.41142544356\n",
            "Loss:  0.03946386695315596\n",
            "E_step lan  52\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  52\n",
            "[ 2019-07-15 01:45:46 ] After the 52 's iteration  \n",
            "Log Likelihood:  -85755.37326906019\n",
            "Loss:  0.03815638336527627\n",
            "E_step lan  53\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  53\n",
            "[ 2019-07-15 01:46:16 ] After the 53 's iteration  \n",
            "Log Likelihood:  -85755.33510295705\n",
            "Loss:  0.038166103142430075\n",
            "E_step lan  54\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  54\n",
            "[ 2019-07-15 01:46:47 ] After the 54 's iteration  \n",
            "Log Likelihood:  -85755.2958780454\n",
            "Loss:  0.03922491164121311\n",
            "E_step lan  55\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  55\n",
            "[ 2019-07-15 01:47:17 ] After the 55 's iteration  \n",
            "Log Likelihood:  -85755.25485844939\n",
            "Loss:  0.04101959601393901\n",
            "E_step lan  56\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  56\n",
            "[ 2019-07-15 01:47:48 ] After the 56 's iteration  \n",
            "Log Likelihood:  -85755.211835719\n",
            "Loss:  0.04302273038774729\n",
            "E_step lan  57\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  57\n",
            "[ 2019-07-15 01:48:18 ] After the 57 's iteration  \n",
            "Log Likelihood:  -85755.16734615015\n",
            "Loss:  0.04448956885607913\n",
            "E_step lan  58\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  58\n",
            "[ 2019-07-15 01:48:49 ] After the 58 's iteration  \n",
            "Log Likelihood:  -85755.12273177893\n",
            "Loss:  0.04461437121790368\n",
            "E_step lan  59\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  59\n",
            "[ 2019-07-15 01:49:20 ] After the 59 's iteration  \n",
            "Log Likelihood:  -85755.07978959449\n",
            "Loss:  0.042942184445564635\n",
            "E_step lan  60\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  60\n",
            "[ 2019-07-15 01:49:50 ] After the 60 's iteration  \n",
            "Log Likelihood:  -85755.03950859123\n",
            "Loss:  0.04028100325376727\n",
            "E_step lan  61\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  61\n",
            "[ 2019-07-15 01:50:20 ] After the 61 's iteration  \n",
            "Log Likelihood:  -85754.99839150812\n",
            "Loss:  0.04111708310665563\n",
            "E_step lan  62\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  62\n",
            "[ 2019-07-15 01:50:51 ] After the 62 's iteration  \n",
            "Log Likelihood:  -85754.9370366373\n",
            "Loss:  0.06135487082065083\n",
            "E_step lan  63\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  63\n",
            "[ 2019-07-15 01:51:22 ] After the 63 's iteration  \n",
            "Log Likelihood:  -85754.79026774774\n",
            "Loss:  0.14676888956455514\n",
            "E_step lan  64\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  64\n",
            "[ 2019-07-15 01:51:52 ] After the 64 's iteration  \n",
            "Log Likelihood:  -85754.4419192166\n",
            "Loss:  0.3483485311444383\n",
            "E_step lan  65\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  65\n",
            "[ 2019-07-15 01:52:22 ] After the 65 's iteration  \n",
            "Log Likelihood:  -85753.95373044662\n",
            "Loss:  0.4881887699739309\n",
            "E_step lan  66\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  66\n",
            "[ 2019-07-15 01:52:53 ] After the 66 's iteration  \n",
            "Log Likelihood:  -85753.6346137156\n",
            "Loss:  0.3191167310142191\n",
            "E_step lan  67\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  67\n",
            "[ 2019-07-15 01:53:23 ] After the 67 's iteration  \n",
            "Log Likelihood:  -85753.5235079549\n",
            "Loss:  0.11110576070495881\n",
            "E_step lan  68\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  68\n",
            "[ 2019-07-15 01:53:54 ] After the 68 's iteration  \n",
            "Log Likelihood:  -85753.49443295767\n",
            "Loss:  0.029074997233692557\n",
            "E_step lan  69\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  69\n",
            "[ 2019-07-15 01:54:25 ] After the 69 's iteration  \n",
            "Log Likelihood:  -85753.48686309694\n",
            "Loss:  0.007569860725197941\n",
            "E_step lan  70\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  70\n",
            "[ 2019-07-15 01:54:55 ] After the 70 's iteration  \n",
            "Log Likelihood:  -85753.48440918728\n",
            "Loss:  0.002453909663017839\n",
            "E_step lan  71\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  71\n",
            "[ 2019-07-15 01:55:26 ] After the 71 's iteration  \n",
            "Log Likelihood:  -85753.48306859768\n",
            "Loss:  0.0013405896024778485\n",
            "E_step lan  72\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  72\n",
            "[ 2019-07-15 01:55:56 ] After the 72 's iteration  \n",
            "Log Likelihood:  -85753.48123591204\n",
            "Loss:  0.001832685637054965\n",
            "E_step lan  73\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  73\n",
            "[ 2019-07-15 01:56:27 ] After the 73 's iteration  \n",
            "Log Likelihood:  -85753.47553512393\n",
            "Loss:  0.005700788111425936\n",
            "E_step lan  74\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  74\n",
            "[ 2019-07-15 01:56:57 ] After the 74 's iteration  \n",
            "Log Likelihood:  -85753.4517047181\n",
            "Loss:  0.023830405829357915\n",
            "E_step lan  75\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  75\n",
            "[ 2019-07-15 01:57:28 ] After the 75 's iteration  \n",
            "Log Likelihood:  -85753.3469933129\n",
            "Loss:  0.10471140520530753\n",
            "E_step lan  76\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  76\n",
            "[ 2019-07-15 01:57:58 ] After the 76 's iteration  \n",
            "Log Likelihood:  -85752.91138270141\n",
            "Loss:  0.4356106114864815\n",
            "E_step lan  77\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  77\n",
            "[ 2019-07-15 01:58:29 ] After the 77 's iteration  \n",
            "Log Likelihood:  -85751.46274528274\n",
            "Loss:  1.4486374186672037\n",
            "E_step lan  78\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  78\n",
            "[ 2019-07-15 01:58:59 ] After the 78 's iteration  \n",
            "Log Likelihood:  -85748.25299341293\n",
            "Loss:  3.209751869813772\n",
            "E_step lan  79\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  79\n",
            "[ 2019-07-15 01:59:30 ] After the 79 's iteration  \n",
            "Log Likelihood:  -85742.42549717122\n",
            "Loss:  5.827496241705376\n",
            "E_step lan  80\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  80\n",
            "[ 2019-07-15 02:00:00 ] After the 80 's iteration  \n",
            "Log Likelihood:  -85736.18493809483\n",
            "Loss:  6.240559076395584\n",
            "E_step lan  81\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  81\n",
            "[ 2019-07-15 02:00:30 ] After the 81 's iteration  \n",
            "Log Likelihood:  -85734.75555873038\n",
            "Loss:  1.429379364446504\n",
            "E_step lan  82\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  82\n",
            "[ 2019-07-15 02:01:01 ] After the 82 's iteration  \n",
            "Log Likelihood:  -85734.69112041869\n",
            "Loss:  0.06443831168871839\n",
            "E_step lan  83\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  83\n",
            "[ 2019-07-15 02:01:31 ] After the 83 's iteration  \n",
            "Log Likelihood:  -85734.67668822933\n",
            "Loss:  0.014432189360377379\n",
            "E_step lan  84\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  84\n",
            "[ 2019-07-15 02:02:02 ] After the 84 's iteration  \n",
            "Log Likelihood:  -85734.6575695882\n",
            "Loss:  0.019118641124805436\n",
            "E_step lan  85\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  85\n",
            "[ 2019-07-15 02:02:32 ] After the 85 's iteration  \n",
            "Log Likelihood:  -85734.63142436388\n",
            "Loss:  0.02614522432850208\n",
            "E_step lan  86\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  86\n",
            "[ 2019-07-15 02:03:03 ] After the 86 's iteration  \n",
            "Log Likelihood:  -85734.59768826031\n",
            "Loss:  0.033736103563569486\n",
            "E_step lan  87\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  87\n",
            "[ 2019-07-15 02:03:33 ] After the 87 's iteration  \n",
            "Log Likelihood:  -85734.55646869002\n",
            "Loss:  0.041219570295652375\n",
            "E_step lan  88\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  88\n",
            "[ 2019-07-15 02:04:04 ] After the 88 's iteration  \n",
            "Log Likelihood:  -85734.5070065471\n",
            "Loss:  0.0494621429243125\n",
            "E_step lan  89\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  89\n",
            "[ 2019-07-15 02:04:34 ] After the 89 's iteration  \n",
            "Log Likelihood:  -85734.44455046064\n",
            "Loss:  0.062456086452584714\n",
            "E_step lan  90\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  90\n",
            "[ 2019-07-15 02:05:05 ] After the 90 's iteration  \n",
            "Log Likelihood:  -85734.35730127776\n",
            "Loss:  0.08724918287771288\n",
            "E_step lan  91\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  91\n",
            "[ 2019-07-15 02:05:35 ] After the 91 's iteration  \n",
            "Log Likelihood:  -85734.22589203545\n",
            "Loss:  0.13140924231265672\n",
            "E_step lan  92\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  92\n",
            "[ 2019-07-15 02:06:06 ] After the 92 's iteration  \n",
            "Log Likelihood:  -85734.02774036811\n",
            "Loss:  0.19815166734042577\n",
            "E_step lan  93\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  93\n",
            "[ 2019-07-15 02:06:37 ] After the 93 's iteration  \n",
            "Log Likelihood:  -85733.74855004181\n",
            "Loss:  0.27919032629870344\n",
            "E_step lan  94\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  94\n",
            "[ 2019-07-15 02:07:07 ] After the 94 's iteration  \n",
            "Log Likelihood:  -85733.3932135461\n",
            "Loss:  0.3553364957188023\n",
            "E_step lan  95\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  95\n",
            "[ 2019-07-15 02:07:38 ] After the 95 's iteration  \n",
            "Log Likelihood:  -85732.88382628627\n",
            "Loss:  0.5093872598226881\n",
            "E_step lan  96\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  96\n",
            "[ 2019-07-15 02:08:08 ] After the 96 's iteration  \n",
            "Log Likelihood:  -85731.20647115061\n",
            "Loss:  1.6773551356600365\n",
            "E_step lan  97\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  97\n",
            "[ 2019-07-15 02:08:38 ] After the 97 's iteration  \n",
            "Log Likelihood:  -85729.2299373819\n",
            "Loss:  1.976533768713125\n",
            "E_step lan  98\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  98\n",
            "[ 2019-07-15 02:09:09 ] After the 98 's iteration  \n",
            "Log Likelihood:  -85728.93976288654\n",
            "Loss:  0.290174495356041\n",
            "E_step lan  99\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  99\n",
            "[ 2019-07-15 02:09:39 ] After the 99 's iteration  \n",
            "Log Likelihood:  -85728.90000828844\n",
            "Loss:  0.039754598095896654\n",
            "E_step lan  100\n",
            "K:  0\n",
            "K:  1\n",
            "K:  2\n",
            "K:  3\n",
            "K:  4\n",
            "M_step lan  100\n",
            "[ 2019-07-15 02:10:10 ] After the 100 's iteration  \n",
            "Log Likelihood:  -85728.87369309098\n",
            "Loss:  0.026315197465009987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMv9ITNiQoNA",
        "colab_type": "code",
        "outputId": "347c3876-135d-448e-c888-98dd1643e92a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(plsa._theta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6.54939525e-087 7.19052202e-061 1.00000000e+000 1.43961266e-074\n",
            "  1.06031844e-084]\n",
            " [9.48452747e-073 1.00000000e+000 4.81719675e-068 9.36475113e-097\n",
            "  2.70784259e-076]\n",
            " [4.52386743e-067 2.77143499e-042 1.00000000e+000 1.56971064e-058\n",
            "  4.76927839e-095]\n",
            " ...\n",
            " [2.56031739e-091 5.89616272e-082 2.19259480e-019 4.02875283e-053\n",
            "  1.00000000e+000]\n",
            " [1.27357806e-112 2.38563675e-131 5.60307235e-140 1.14320365e-114\n",
            "  1.00000000e+000]\n",
            " [4.13367425e-124 1.68635590e-120 2.19952380e-093 1.00000000e+000\n",
            "  6.33617693e-076]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqHFzbBDdRG5",
        "colab_type": "code",
        "outputId": "00569f80-5dee-4b52-a0d6-52a63d2b7d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "plsa._theta.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(249, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlpOIpqoeSgi",
        "colab_type": "code",
        "outputId": "d8f50d3c-bd46-4154-8f2d-03a9e6c9c01d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "np.argsort(plsa._theta)[:, -1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 2, 0, 0, 1, 4, 1, 0, 4, 4, 3, 0, 1, 4, 2, 4, 4, 4, 1, 0, 0,\n",
              "       0, 4, 0, 4, 3, 3, 3, 3, 4, 4, 4, 2, 4, 0, 0, 0, 3, 1, 4, 0, 0, 3,\n",
              "       4, 1, 2, 0, 0, 0, 2, 3, 0, 4, 0, 0, 4, 0, 0, 4, 3, 0, 4, 2, 1, 3,\n",
              "       2, 3, 4, 1, 2, 1, 2, 3, 3, 3, 0, 4, 2, 3, 2, 0, 4, 3, 2, 0, 2, 2,\n",
              "       3, 3, 2, 3, 3, 2, 1, 0, 3, 0, 1, 0, 1, 2, 0, 2, 0, 4, 0, 3, 0, 3,\n",
              "       1, 4, 0, 1, 0, 3, 3, 1, 0, 4, 3, 4, 3, 2, 4, 3, 2, 1, 2, 0, 2, 0,\n",
              "       3, 1, 0, 3, 1, 2, 3, 0, 4, 0, 1, 3, 4, 3, 1, 4, 4, 0, 3, 3, 3, 1,\n",
              "       0, 4, 4, 4, 0, 3, 1, 4, 1, 4, 4, 0, 0, 2, 0, 3, 4, 3, 4, 1, 4, 3,\n",
              "       0, 1, 2, 1, 1, 1, 0, 1, 4, 2, 0, 4, 2, 0, 4, 2, 4, 1, 2, 4, 0, 1,\n",
              "       1, 1, 2, 2, 3, 1, 0, 0, 0, 0, 3, 4, 0, 0, 4, 1, 1, 4, 4, 4, 3, 1,\n",
              "       1, 3, 3, 1, 3, 4, 0, 1, 4, 1, 4, 3, 1, 3, 4, 0, 2, 1, 4, 2, 0, 3,\n",
              "       1, 0, 2, 1, 4, 4, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a3Xn_u8bCi2",
        "colab_type": "code",
        "outputId": "f6eef53c-c5cc-4b3d-a352-e05bebde521d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(plsa._beta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.0007073  0.         0.00035365]\n",
            " [0.00038754 0.00038754 0.00077507 ... 0.         0.         0.00038754]\n",
            " [0.         0.         0.         ... 0.         0.00103508 0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw9AziR5bJch",
        "colab_type": "code",
        "outputId": "d8c17fd1-1480-4241-8e80-d6a657f01299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "np.argsort(plsa._beta)[:, -10:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2605, 5318, 3271, 4701, 5330, 3190, 3830, 4430, 4859, 2855],\n",
              "       [3237,  235, 3382, 3964,  427, 2178, 4341, 4144, 5434, 5124],\n",
              "       [3563, 3094, 2660, 2531, 3469, 1921, 2204, 1152, 1878, 4283],\n",
              "       [4469, 4926, 4047, 3468, 3977, 5508, 3210, 1537, 2690, 5538],\n",
              "       [ 605, 4528, 5355, 5551, 1340, 4324, 2827,  762, 2744, 1630]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SkdhFG0fYHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/gdrive/My Drive/PLSA/vocab.txt', errors = 'ignore') as f:\n",
        "  vocab = f.read().splitlines()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T17E6wwaf43Z",
        "colab_type": "code",
        "outputId": "2f2363d9-a00c-4805-b13a-ef1517e65cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aa',\n",
              " 'aah',\n",
              " 'aap',\n",
              " 'aaron',\n",
              " 'ab',\n",
              " 'abortions',\n",
              " 'absence',\n",
              " 'absolute',\n",
              " 'abstact',\n",
              " 'abstract',\n",
              " 'abstracts',\n",
              " 'absurd',\n",
              " 'absurdities',\n",
              " 'abyte',\n",
              " 'academic',\n",
              " 'accelerated',\n",
              " 'accelerators',\n",
              " 'accellerator',\n",
              " 'acceptable',\n",
              " 'acceptance',\n",
              " 'accepting',\n",
              " 'accepts',\n",
              " 'accessed',\n",
              " 'accessible',\n",
              " 'accident',\n",
              " 'accidental',\n",
              " 'accidents',\n",
              " 'accompanied',\n",
              " 'accomplishment',\n",
              " 'accor',\n",
              " 'accounts',\n",
              " 'accurately',\n",
              " 'achieve',\n",
              " 'acooper',\n",
              " 'acquired',\n",
              " 'acquisition',\n",
              " 'across',\n",
              " 'action',\n",
              " 'actions',\n",
              " 'active',\n",
              " 'actively',\n",
              " 'activity',\n",
              " 'acts',\n",
              " 'actual',\n",
              " 'ad',\n",
              " 'adam',\n",
              " 'adams',\n",
              " 'adaptabtion',\n",
              " 'adaptec',\n",
              " 'adapters',\n",
              " 'adb',\n",
              " 'added',\n",
              " 'addendum',\n",
              " 'adding',\n",
              " 'addition',\n",
              " 'addressed',\n",
              " 'addressing',\n",
              " 'adequate',\n",
              " 'adequately',\n",
              " 'adherence',\n",
              " 'adherent',\n",
              " 'adjusted',\n",
              " 'administer',\n",
              " 'administers',\n",
              " 'administrative',\n",
              " 'administrator',\n",
              " 'admit',\n",
              " 'admitted',\n",
              " 'admittedly',\n",
              " 'admitting',\n",
              " 'adobe',\n",
              " 'adopt',\n",
              " 'adresses',\n",
              " 'adriene',\n",
              " 'ads',\n",
              " 'adult',\n",
              " 'adulteries',\n",
              " 'advanced',\n",
              " 'advantage',\n",
              " 'advertise',\n",
              " 'advertisements',\n",
              " 'advertising',\n",
              " 'advises',\n",
              " 'advisor',\n",
              " 'advocate',\n",
              " 'aesthetics',\n",
              " 'affiliations',\n",
              " 'affordable',\n",
              " 'african',\n",
              " 'afternoons',\n",
              " 'afterwards',\n",
              " 'age',\n",
              " 'ages',\n",
              " 'agnostic',\n",
              " 'agnosticism',\n",
              " 'agreed',\n",
              " 'ah',\n",
              " 'ahead',\n",
              " 'aid',\n",
              " 'aids',\n",
              " 'aio',\n",
              " 'air',\n",
              " 'airlines',\n",
              " 'aix',\n",
              " 'ajacobs',\n",
              " 'ala',\n",
              " 'alabama',\n",
              " 'alain',\n",
              " 'albatross',\n",
              " 'albeit',\n",
              " 'alberta',\n",
              " 'albuquerque',\n",
              " 'aldridge',\n",
              " 'alex',\n",
              " 'alexander',\n",
              " 'algorithm',\n",
              " 'aliases',\n",
              " 'alien',\n",
              " 'align',\n",
              " 'alive',\n",
              " 'allah',\n",
              " 'allegiance',\n",
              " 'allegory',\n",
              " 'allen',\n",
              " 'allergic',\n",
              " 'allerton',\n",
              " 'allocated',\n",
              " 'allowed',\n",
              " 'allowing',\n",
              " 'almondsbury',\n",
              " 'alogorythmn',\n",
              " 'alone',\n",
              " 'alot',\n",
              " 'alpha',\n",
              " 'alternate',\n",
              " 'alternatives',\n",
              " 'alverson',\n",
              " 'amateur',\n",
              " 'amazing',\n",
              " 'amd',\n",
              " 'americans',\n",
              " 'ames',\n",
              " 'amex',\n",
              " 'amherst',\n",
              " 'ami',\n",
              " 'amiga',\n",
              " 'amipro',\n",
              " 'amish',\n",
              " 'among',\n",
              " 'amongst',\n",
              " 'amounts',\n",
              " 'amsterdam',\n",
              " 'amstrad',\n",
              " 'amusing',\n",
              " 'anaesthesie',\n",
              " 'anaesthesiologie',\n",
              " 'anal',\n",
              " 'analogy',\n",
              " 'analysis',\n",
              " 'ance',\n",
              " 'ancient',\n",
              " 'andre',\n",
              " 'andreas',\n",
              " 'andrei',\n",
              " 'andrey',\n",
              " 'andy',\n",
              " 'anecdote',\n",
              " 'anfd',\n",
              " 'ani',\n",
              " 'animals',\n",
              " 'animated',\n",
              " 'animation',\n",
              " 'animations',\n",
              " 'animator',\n",
              " 'annex',\n",
              " 'announced',\n",
              " 'announcement',\n",
              " 'announcementof',\n",
              " 'annoying',\n",
              " 'anonymous',\n",
              " 'anonyomus',\n",
              " 'anselm',\n",
              " 'ansi',\n",
              " 'answered',\n",
              " 'answering',\n",
              " 'answers',\n",
              " 'anthology',\n",
              " 'anthropo',\n",
              " 'anthropomorphise',\n",
              " 'antibigot',\n",
              " 'antipathy',\n",
              " 'antiquated',\n",
              " 'anybodys',\n",
              " 'anymore',\n",
              " 'anyways',\n",
              " 'anywhere',\n",
              " 'apana',\n",
              " 'apart',\n",
              " 'aperture',\n",
              " 'apologies',\n",
              " 'apologize',\n",
              " 'apparantly',\n",
              " 'apparent',\n",
              " 'appeal',\n",
              " 'appeals',\n",
              " 'appear',\n",
              " 'appearance',\n",
              " 'appeared',\n",
              " 'appears',\n",
              " 'append',\n",
              " 'appendix',\n",
              " 'apples',\n",
              " 'appleshare',\n",
              " 'appletalk',\n",
              " 'applicable',\n",
              " 'application',\n",
              " 'applied',\n",
              " 'applies',\n",
              " 'applying',\n",
              " 'appologize',\n",
              " 'apppreciated',\n",
              " 'approach',\n",
              " 'approachable',\n",
              " 'appropriate',\n",
              " 'approve',\n",
              " 'approximate',\n",
              " 'approximately',\n",
              " 'approximation',\n",
              " 'apps',\n",
              " 'aqe',\n",
              " 'arabia',\n",
              " 'arain',\n",
              " 'aranda',\n",
              " 'arbitary',\n",
              " 'arbitrary',\n",
              " 'arbor',\n",
              " 'archie',\n",
              " 'architecture',\n",
              " 'archive',\n",
              " 'archives',\n",
              " 'archiving',\n",
              " 'ardie',\n",
              " 'areas',\n",
              " 'arguable',\n",
              " 'arguably',\n",
              " 'argues',\n",
              " 'arguing',\n",
              " 'ari',\n",
              " 'arial',\n",
              " 'arizona',\n",
              " 'arj',\n",
              " 'arjed',\n",
              " 'arkansas',\n",
              " 'armstrong',\n",
              " 'arnd',\n",
              " 'arpa',\n",
              " 'arrays',\n",
              " 'arrived',\n",
              " 'arrives',\n",
              " 'arromdee',\n",
              " 'arrow',\n",
              " 'arrowheads',\n",
              " 'arrows',\n",
              " 'art',\n",
              " 'articles',\n",
              " 'artificial',\n",
              " 'artist',\n",
              " 'arts',\n",
              " 'asad',\n",
              " 'ascii',\n",
              " 'ascribe',\n",
              " 'asic',\n",
              " 'aside',\n",
              " 'asks',\n",
              " 'asm',\n",
              " 'asp',\n",
              " 'aspect',\n",
              " 'aspects',\n",
              " 'ass',\n",
              " 'assassinated',\n",
              " 'assembled',\n",
              " 'assembler',\n",
              " 'assembly',\n",
              " 'assertained',\n",
              " 'asserting',\n",
              " 'assertion',\n",
              " 'assertions',\n",
              " 'asserts',\n",
              " 'assign',\n",
              " 'assigns',\n",
              " 'assist',\n",
              " 'assistant',\n",
              " 'assisted',\n",
              " 'associated',\n",
              " 'association',\n",
              " 'assorted',\n",
              " 'assumed',\n",
              " 'assumes',\n",
              " 'assumption',\n",
              " 'assumptions',\n",
              " 'astrology',\n",
              " 'asts',\n",
              " 'async',\n",
              " 'asyvan',\n",
              " 'atari',\n",
              " 'atheisten',\n",
              " 'atheistic',\n",
              " 'atm',\n",
              " 'atomic',\n",
              " 'atoms',\n",
              " 'atrocities',\n",
              " 'attach',\n",
              " 'attached',\n",
              " 'attachment',\n",
              " 'attack',\n",
              " 'attacks',\n",
              " 'attempting',\n",
              " 'attempts',\n",
              " 'attend',\n",
              " 'attendees',\n",
              " 'attention',\n",
              " 'attitude',\n",
              " 'attitudes',\n",
              " 'attn',\n",
              " 'attribute',\n",
              " 'attributes',\n",
              " 'attributions',\n",
              " 'atwood',\n",
              " 'audio',\n",
              " 'audion',\n",
              " 'augustana',\n",
              " 'australasian',\n",
              " 'australia',\n",
              " 'australian',\n",
              " 'authoring',\n",
              " 'authority',\n",
              " 'auto',\n",
              " 'autocad',\n",
              " 'autodesk',\n",
              " 'automatically',\n",
              " 'automobile',\n",
              " 'avaliable',\n",
              " 'ave',\n",
              " 'average',\n",
              " 'avoiding',\n",
              " 'aw',\n",
              " 'aware',\n",
              " 'awesome',\n",
              " 'axes',\n",
              " 'axiarchism',\n",
              " 'ay',\n",
              " 'aztec',\n",
              " 'babak',\n",
              " 'babcock',\n",
              " 'backed',\n",
              " 'background',\n",
              " 'backgrounds',\n",
              " 'backing',\n",
              " 'backlash',\n",
              " 'backspace',\n",
              " 'backwards',\n",
              " 'badges',\n",
              " 'badly',\n",
              " 'bag',\n",
              " 'ball',\n",
              " 'ballantine',\n",
              " 'ballot',\n",
              " 'baltimore',\n",
              " 'banding',\n",
              " 'bands',\n",
              " 'bandwidth',\n",
              " 'bang',\n",
              " 'banged',\n",
              " 'bank',\n",
              " 'banks',\n",
              " 'banner',\n",
              " 'banshee',\n",
              " 'bantam',\n",
              " 'baptist',\n",
              " 'barbara',\n",
              " 'barnsley',\n",
              " 'barton',\n",
              " 'barwick',\n",
              " 'base',\n",
              " 'baseball',\n",
              " 'basin',\n",
              " 'basing',\n",
              " 'basis',\n",
              " 'bastard',\n",
              " 'bathroom',\n",
              " 'batteries',\n",
              " 'battery',\n",
              " 'baud',\n",
              " 'bauer',\n",
              " 'bay',\n",
              " 'bboard',\n",
              " 'bcc',\n",
              " 'bdunn',\n",
              " 'beam',\n",
              " 'bear',\n",
              " 'bearing',\n",
              " 'beast',\n",
              " 'beat',\n",
              " 'beautiful',\n",
              " 'beaverton',\n",
              " 'became',\n",
              " 'becomes',\n",
              " 'becoming',\n",
              " 'becomming',\n",
              " 'becuase',\n",
              " 'bedroom',\n",
              " 'beg',\n",
              " 'began',\n",
              " 'beginer',\n",
              " 'beginning',\n",
              " 'beginnings',\n",
              " 'begins',\n",
              " 'begs',\n",
              " 'behave',\n",
              " 'behavior',\n",
              " 'behaviors',\n",
              " 'behaviour',\n",
              " 'behind',\n",
              " 'bei',\n",
              " 'beings',\n",
              " 'beleive',\n",
              " 'believer',\n",
              " 'believers',\n",
              " 'believes',\n",
              " 'believing',\n",
              " 'bell',\n",
              " 'belmonte',\n",
              " 'belt',\n",
              " 'benchmarked',\n",
              " 'benchmarks',\n",
              " 'beneath',\n",
              " 'benedikt',\n",
              " 'benefit',\n",
              " 'benefits',\n",
              " 'berkeley',\n",
              " 'berlin',\n",
              " 'bernoulli',\n",
              " 'berthold',\n",
              " 'bet',\n",
              " 'beta',\n",
              " 'bethesda',\n",
              " 'betwen',\n",
              " 'bevans',\n",
              " 'beware',\n",
              " 'bgi',\n",
              " 'bgsu',\n",
              " 'biased',\n",
              " 'biblical',\n",
              " 'bibliography',\n",
              " 'bigal',\n",
              " 'bigger',\n",
              " 'biggest',\n",
              " 'biginning',\n",
              " 'billing',\n",
              " 'billions',\n",
              " 'binar',\n",
              " 'binary',\n",
              " 'bind',\n",
              " 'binder',\n",
              " 'binhex',\n",
              " 'binhexed',\n",
              " 'bioscom',\n",
              " 'birth',\n",
              " 'birthday',\n",
              " 'births',\n",
              " 'bitblt',\n",
              " 'bitma',\n",
              " 'bitmap',\n",
              " 'bitmaps',\n",
              " 'bix',\n",
              " 'bizarre',\n",
              " 'bjorndahl',\n",
              " 'bk',\n",
              " 'bkph',\n",
              " 'blacklisted',\n",
              " 'blanks',\n",
              " 'blaster',\n",
              " 'blatantly',\n",
              " 'blazingly',\n",
              " 'blender',\n",
              " 'blew',\n",
              " 'blind',\n",
              " 'blink',\n",
              " 'blitz',\n",
              " 'bloc',\n",
              " 'block',\n",
              " 'blocked',\n",
              " 'blocks',\n",
              " 'blood',\n",
              " 'blow',\n",
              " 'blowin',\n",
              " 'blue',\n",
              " 'blueprints',\n",
              " 'boards',\n",
              " 'boat',\n",
              " 'bobmon',\n",
              " 'bobs',\n",
              " 'boca',\n",
              " 'bodnar',\n",
              " 'body',\n",
              " 'bogart',\n",
              " 'bold',\n",
              " 'boldface',\n",
              " 'bolsters',\n",
              " 'bondage',\n",
              " 'books',\n",
              " 'bootup',\n",
              " 'borland',\n",
              " 'born',\n",
              " 'borrow',\n",
              " 'borrowing',\n",
              " 'bos',\n",
              " 'boss',\n",
              " 'boston',\n",
              " 'bother',\n",
              " 'bothering',\n",
              " 'bottoming',\n",
              " 'boulder',\n",
              " 'boxes',\n",
              " 'boy',\n",
              " 'boycott',\n",
              " 'boyd',\n",
              " 'bprofane',\n",
              " 'bps',\n",
              " 'brad',\n",
              " 'brain',\n",
              " 'branch',\n",
              " 'branches',\n",
              " 'brand',\n",
              " 'brant',\n",
              " 'brante',\n",
              " 'bratcher',\n",
              " 'braunschweig',\n",
              " 'bravo',\n",
              " 'break',\n",
              " 'breath',\n",
              " 'brendan',\n",
              " 'bret',\n",
              " 'brian',\n",
              " 'brick',\n",
              " 'brief',\n",
              " 'brighter',\n",
              " 'brightnesses',\n",
              " 'brilliant',\n",
              " 'bring',\n",
              " 'brings',\n",
              " 'bristol',\n",
              " 'britain',\n",
              " 'british',\n",
              " 'broad',\n",
              " 'broadway',\n",
              " 'broken',\n",
              " 'bronx',\n",
              " 'brooks',\n",
              " 'brother',\n",
              " 'brought',\n",
              " 'brown',\n",
              " 'brownian',\n",
              " 'bruce',\n",
              " 'bruceg',\n",
              " 'brush',\n",
              " 'bryan',\n",
              " 'bsa',\n",
              " 'btw',\n",
              " 'buddhism',\n",
              " 'buddhists',\n",
              " 'buddism',\n",
              " 'buddy',\n",
              " 'buffalo',\n",
              " 'buffer',\n",
              " 'buggy',\n",
              " 'bugs',\n",
              " 'build',\n",
              " 'building',\n",
              " 'buildings',\n",
              " 'built',\n",
              " 'bull',\n",
              " 'bullet',\n",
              " 'bulletin',\n",
              " 'bullshitting',\n",
              " 'bulut',\n",
              " 'bumper',\n",
              " 'bunch',\n",
              " 'bund',\n",
              " 'bundle',\n",
              " 'bundled',\n",
              " 'burdens',\n",
              " 'burghardt',\n",
              " 'burned',\n",
              " 'busy',\n",
              " 'buttons',\n",
              " 'butzen',\n",
              " 'buying',\n",
              " 'bw',\n",
              " 'bwelch',\n",
              " 'bylaws',\n",
              " 'byoh',\n",
              " 'byrne',\n",
              " 'byte',\n",
              " 'bytes',\n",
              " 'cable',\n",
              " 'cables',\n",
              " 'cabling',\n",
              " 'caches',\n",
              " 'caching',\n",
              " 'caere',\n",
              " 'cage',\n",
              " 'cajon',\n",
              " 'calculate',\n",
              " 'calculated',\n",
              " 'calculation',\n",
              " 'calculations',\n",
              " 'caliber',\n",
              " 'calling',\n",
              " 'calls',\n",
              " 'calm',\n",
              " 'calvin',\n",
              " 'camera',\n",
              " 'cameron',\n",
              " 'camp',\n",
              " 'campaign',\n",
              " 'campaigning',\n",
              " 'campaigns',\n",
              " 'campus',\n",
              " 'camrose',\n",
              " 'cancel',\n",
              " 'cannibal',\n",
              " 'canon',\n",
              " 'canterbury',\n",
              " 'canticle',\n",
              " 'canyon',\n",
              " 'cap',\n",
              " 'capabilities',\n",
              " 'capability',\n",
              " 'capable',\n",
              " 'capitals',\n",
              " 'caps',\n",
              " 'caputo',\n",
              " 'car',\n",
              " 'carderock',\n",
              " 'cardiff',\n",
              " 'cared',\n",
              " 'careful',\n",
              " 'carelcomp',\n",
              " 'carl',\n",
              " 'carol',\n",
              " 'carolina',\n",
              " 'caroline',\n",
              " 'carols',\n",
              " 'carpeting',\n",
              " 'carry',\n",
              " 'carrying',\n",
              " 'cars',\n",
              " 'cartoon',\n",
              " 'cartridge',\n",
              " 'casbah',\n",
              " 'cases',\n",
              " 'casts',\n",
              " 'catalog',\n",
              " 'catalyst',\n",
              " 'catch',\n",
              " 'categories',\n",
              " 'categorization',\n",
              " 'categorized',\n",
              " 'cathedral',\n",
              " 'catholic',\n",
              " 'cats',\n",
              " 'caught',\n",
              " 'caused',\n",
              " 'causing',\n",
              " 'cavalier',\n",
              " 'cavallino',\n",
              " 'caveat',\n",
              " 'cc',\n",
              " 'ccmail',\n",
              " 'cd',\n",
              " 'cdi',\n",
              " 'cdnswc',\n",
              " 'cdt',\n",
              " 'ce',\n",
              " 'ceasing',\n",
              " 'cebit',\n",
              " 'cedar',\n",
              " 'cee',\n",
              " 'cell',\n",
              " 'censwm',\n",
              " 'centigram',\n",
              " 'centre',\n",
              " 'centuries',\n",
              " 'century',\n",
              " 'ceo',\n",
              " 'cept',\n",
              " 'ceremonies',\n",
              " 'certainty',\n",
              " 'cesspool',\n",
              " 'cgd',\n",
              " 'chad',\n",
              " 'chair',\n",
              " 'chairman',\n",
              " 'challenging',\n",
              " 'chalmers',\n",
              " 'chance',\n",
              " 'chances',\n",
              " 'changed',\n",
              " 'changes',\n",
              " 'changing',\n",
              " 'channels',\n",
              " 'char',\n",
              " 'character',\n",
              " 'characteristic',\n",
              " 'characteristics',\n",
              " 'characterized',\n",
              " 'charge',\n",
              " 'charities',\n",
              " 'charity',\n",
              " 'charles',\n",
              " 'charley',\n",
              " 'charlie',\n",
              " 'charm',\n",
              " 'charter',\n",
              " 'chasing',\n",
              " 'cheaper',\n",
              " 'cheating',\n",
              " 'cheats',\n",
              " 'checked',\n",
              " 'checker',\n",
              " 'checks',\n",
              " 'cheep',\n",
              " 'cheers',\n",
              " 'chemistry',\n",
              " 'chen',\n",
              " 'cheng',\n",
              " 'chevron',\n",
              " 'chief',\n",
              " 'children',\n",
              " 'chilling',\n",
              " 'choices',\n",
              " 'choises',\n",
              " 'chooses',\n",
              " 'chose',\n",
              " 'chosen',\n",
              " 'chould',\n",
              " 'chpp',\n",
              " 'chris',\n",
              " 'christ',\n",
              " 'christchurch',\n",
              " 'christen',\n",
              " 'christensen',\n",
              " 'christianity',\n",
              " 'christians',\n",
              " 'chua',\n",
              " 'chunk',\n",
              " 'chunks',\n",
              " 'church',\n",
              " 'churches',\n",
              " 'ci',\n",
              " 'cica',\n",
              " 'cie',\n",
              " 'circa',\n",
              " 'circle',\n",
              " 'circuitry',\n",
              " 'circuits',\n",
              " 'circular',\n",
              " 'circumstances',\n",
              " 'circumstantial',\n",
              " 'circumvent',\n",
              " 'cited',\n",
              " 'citibank',\n",
              " 'citizens',\n",
              " 'city',\n",
              " 'civil',\n",
              " 'civilization',\n",
              " 'claimed',\n",
              " 'claiming',\n",
              " 'claims',\n",
              " 'claremont',\n",
              " 'clarendon',\n",
              " 'clarification',\n",
              " 'clarity',\n",
              " 'clark',\n",
              " 'clarke',\n",
              " 'clarkec',\n",
              " 'class',\n",
              " 'classed',\n",
              " 'classes',\n",
              " 'classic',\n",
              " 'classical',\n",
              " 'claus',\n",
              " 'claws',\n",
              " 'clean',\n",
              " 'cleaning',\n",
              " 'clearing',\n",
              " 'clears',\n",
              " 'clerical',\n",
              " 'cleveland',\n",
              " 'clever',\n",
              " 'click',\n",
              " 'client',\n",
              " 'clinicaly',\n",
              " 'clinton',\n",
              " 'clippingdale',\n",
              " 'clips',\n",
              " 'clock',\n",
              " 'clockwise',\n",
              " 'clone',\n",
              " 'clones',\n",
              " 'closed',\n",
              " 'closely',\n",
              " 'closer',\n",
              " 'clothe',\n",
              " 'cloud',\n",
              " 'club',\n",
              " 'clue',\n",
              " 'clueless',\n",
              " 'cmf',\n",
              " 'cmmiller',\n",
              " 'cmos',\n",
              " 'cn',\n",
              " 'cna',\n",
              " 'co',\n",
              " 'cod',\n",
              " 'codepage',\n",
              " 'codes',\n",
              " 'codified',\n",
              " 'coding',\n",
              " 'coexist',\n",
              " 'coffee',\n",
              " 'cohen',\n",
              " 'coherence',\n",
              " 'cohesion',\n",
              " 'coincidental',\n",
              " 'coined',\n",
              " 'coins',\n",
              " 'coleman',\n",
              " 'colfelt',\n",
              " 'colleague',\n",
              " 'collect',\n",
              " 'collective',\n",
              " 'collins',\n",
              " 'colon',\n",
              " 'colorado',\n",
              " 'colored',\n",
              " 'colorlink',\n",
              " 'colors',\n",
              " 'colour',\n",
              " 'coloured',\n",
              " 'colourmap',\n",
              " 'colours',\n",
              " 'columbia',\n",
              " 'column',\n",
              " 'columns',\n",
              " 'com',\n",
              " 'coma',\n",
              " 'combinations',\n",
              " 'combine',\n",
              " 'combo',\n",
              " 'comdex',\n",
              " 'comedy',\n",
              " 'comfort',\n",
              " 'comfortable',\n",
              " 'comforting',\n",
              " 'comm',\n",
              " 'command',\n",
              " 'commands',\n",
              " 'commas',\n",
              " 'comment',\n",
              " 'commented',\n",
              " 'commercially',\n",
              " 'commerical',\n",
              " 'commission',\n",
              " 'commit',\n",
              " 'commited',\n",
              " 'committed',\n",
              " 'committs',\n",
              " 'commonly',\n",
              " 'comms',\n",
              " 'communicate',\n",
              " 'communicating',\n",
              " 'communication',\n",
              " 'communism',\n",
              " 'communists',\n",
              " 'comp',\n",
              " 'compact',\n",
              " 'compadible',\n",
              " 'companie',\n",
              " 'companies',\n",
              " 'companion',\n",
              " 'compaq',\n",
              " 'comparable',\n",
              " 'comparative',\n",
              " 'compare',\n",
              " 'compared',\n",
              " 'comparisons',\n",
              " 'compassion',\n",
              " 'compassionate',\n",
              " 'compatable',\n",
              " 'compatibility',\n",
              " 'compatibles',\n",
              " 'compatiblity',\n",
              " 'compelling',\n",
              " 'competent',\n",
              " 'competing',\n",
              " 'competition',\n",
              " 'compilation',\n",
              " 'compiled',\n",
              " 'compiler',\n",
              " 'compinations',\n",
              " 'complain',\n",
              " 'complains',\n",
              " 'complaints',\n",
              " 'complement',\n",
              " 'complex',\n",
              " 'complexity',\n",
              " 'complicated',\n",
              " 'comply',\n",
              " 'compose',\n",
              " 'comprehend',\n",
              " 'comprehensive',\n",
              " 'comprendo',\n",
              " 'compress',\n",
              " 'compressed',\n",
              " 'compressible',\n",
              " 'compressing',\n",
              " 'compression',\n",
              " 'compressor',\n",
              " 'compromise',\n",
              " 'compuserve',\n",
              " 'computational',\n",
              " 'computervision',\n",
              " 'computing',\n",
              " 'con',\n",
              " 'conceivable',\n",
              " 'conceived',\n",
              " 'concentrating',\n",
              " 'concepts',\n",
              " 'concern',\n",
              " 'concerning',\n",
              " 'concidered',\n",
              " 'conclude',\n",
              " 'concluded',\n",
              " 'conclusion',\n",
              " 'conclusions',\n",
              " 'conclusively',\n",
              " 'concurrent',\n",
              " 'concurrently',\n",
              " 'condescending',\n",
              " 'condition',\n",
              " 'conditions',\n",
              " 'condoms',\n",
              " 'conduct',\n",
              " 'conducted',\n",
              " 'conduit',\n",
              " 'configurable',\n",
              " 'configurations',\n",
              " 'configure',\n",
              " 'configured',\n",
              " 'configuring',\n",
              " 'confirmed',\n",
              " 'conflict',\n",
              " 'conflicting',\n",
              " 'conforming',\n",
              " 'conformism',\n",
              " 'confront',\n",
              " 'confused',\n",
              " 'congress',\n",
              " 'connecticut',\n",
              " 'connection',\n",
              " 'connections',\n",
              " 'connectix',\n",
              " 'connector',\n",
              " 'connectors',\n",
              " 'connects',\n",
              " 'conscious',\n",
              " 'consensus',\n",
              " 'consequence',\n",
              " 'consequences',\n",
              " 'conserve',\n",
              " 'considdered',\n",
              " 'consider',\n",
              " 'considerably',\n",
              " 'consideration',\n",
              " 'considering',\n",
              " 'considers',\n",
              " 'consistency',\n",
              " 'consistent',\n",
              " 'consistently',\n",
              " 'consolation',\n",
              " 'constant',\n",
              " 'constraints',\n",
              " 'construct',\n",
              " 'consultants',\n",
              " 'consulted',\n",
              " 'consulting',\n",
              " 'consumer',\n",
              " 'contacted',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YxFGaZ0f9hq",
        "colab_type": "code",
        "outputId": "ce9d3c18-c37a-41f4-985c-5298d1eab0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "k = 0\n",
        "for t in np.argsort(plsa._beta)[:, -10:]:\n",
        "  print('Topic ', k)\n",
        "  print('-----')\n",
        "  for w in t:\n",
        "    print(vocab[w])\n",
        "  k += 1\n",
        "  print('*****')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic  0\n",
            "-----\n",
            "jason\n",
            "virtual\n",
            "navy\n",
            "sta\n",
            "visualization\n",
            "morality\n",
            "presentations\n",
            "seminar\n",
            "swap\n",
            "lipman\n",
            "*****\n",
            "Topic  1\n",
            "-----\n",
            "muslims\n",
            "arbor\n",
            "nutek\n",
            "purchase\n",
            "believers\n",
            "harddisk\n",
            "satan\n",
            "religions\n",
            "wide\n",
            "tt\n",
            "*****\n",
            "Topic  2\n",
            "-----\n",
            "parameters\n",
            "mfm\n",
            "jumper\n",
            "interleave\n",
            "optional\n",
            "formatting\n",
            "heads\n",
            "cylinders\n",
            "floppy\n",
            "rom\n",
            "*****\n",
            "Topic  3\n",
            "-----\n",
            "sg\n",
            "td\n",
            "rd\n",
            "option\n",
            "q\n",
            "wsm\n",
            "movie\n",
            "edge\n",
            "keyboard\n",
            "yap\n",
            "*****\n",
            "Topic  4\n",
            "-----\n",
            "cable\n",
            "signal\n",
            "vram\n",
            "youth\n",
            "diamond\n",
            "sale\n",
            "lex\n",
            "cie\n",
            "la\n",
            "enviroleague\n",
            "*****\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}